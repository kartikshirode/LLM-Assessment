{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a996a310",
   "metadata": {},
   "source": [
    "# 02 Sentiment Analysis\n",
    "\n",
    "This notebook performs sentiment analysis on the email dataset using NLP techniques. We'll classify emails into Positive, Negative, or Neutral sentiments using both rule-based and machine learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350cd90",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2abdc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60768db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download VADER lexicon if not already downloaded\n",
    "try:\n",
    "    nltk.data.find('vader_lexicon')\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728134a",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/email_data_processed.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd4f29",
   "metadata": {},
   "source": [
    "## 3. Rule-Based Sentiment Analysis (TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_textblob(text):\n",
    "    \"\"\"Get sentiment using TextBlob\"\"\"\n",
    "    blob = TextBlob(str(text))\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    if polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "def get_sentiment_vader(text):\n",
    "    \"\"\"Get sentiment using VADER\"\"\"\n",
    "    scores = vader_analyzer.polarity_scores(str(text))\n",
    "    compound = scores['compound']\n",
    "    \n",
    "    if compound >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "def get_combined_sentiment(text):\n",
    "    \"\"\"Combine TextBlob and VADER for more robust sentiment classification\"\"\"\n",
    "    textblob_sentiment = get_sentiment_textblob(text)\n",
    "    vader_sentiment = get_sentiment_vader(text)\n",
    "    \n",
    "    # If both agree, use their result\n",
    "    if textblob_sentiment == vader_sentiment:\n",
    "        return textblob_sentiment\n",
    "    \n",
    "    # If they disagree, use VADER (generally more robust for social media/informal text)\n",
    "    # But if one is neutral and other is not, use the non-neutral\n",
    "    if textblob_sentiment == 'Neutral':\n",
    "        return vader_sentiment\n",
    "    elif vader_sentiment == 'Neutral':\n",
    "        return textblob_sentiment\n",
    "    else:\n",
    "        # Both are non-neutral but different, use VADER\n",
    "        return vader_sentiment\n",
    "\n",
    "def get_polarity_scores(text):\n",
    "    \"\"\"Get detailed polarity scores\"\"\"\n",
    "    blob = TextBlob(str(text))\n",
    "    vader_scores = vader_analyzer.polarity_scores(str(text))\n",
    "    \n",
    "    return {\n",
    "        'textblob_polarity': blob.sentiment.polarity,\n",
    "        'textblob_subjectivity': blob.sentiment.subjectivity,\n",
    "        'vader_compound': vader_scores['compound'],\n",
    "        'vader_positive': vader_scores['pos'],\n",
    "        'vader_negative': vader_scores['neg'],\n",
    "        'vader_neutral': vader_scores['neu']\n",
    "    }\n",
    "\n",
    "# Apply sentiment analysis to the dataset\n",
    "print(\"Applying sentiment analysis...\")\n",
    "df['sentiment_textblob'] = df['combined_text'].apply(get_sentiment_textblob)\n",
    "df['sentiment_vader'] = df['combined_text'].apply(get_sentiment_vader)\n",
    "df['sentiment_final'] = df['combined_text'].apply(get_combined_sentiment)\n",
    "\n",
    "# Get detailed scores for analysis\n",
    "polarity_scores = df['combined_text'].apply(get_polarity_scores)\n",
    "polarity_df = pd.json_normalize(polarity_scores)\n",
    "df = pd.concat([df, polarity_df], axis=1)\n",
    "\n",
    "print(\"Sentiment analysis completed!\")\n",
    "print(f\"\\nSentiment Distribution (TextBlob):\")\n",
    "print(df['sentiment_textblob'].value_counts())\n",
    "print(f\"\\nSentiment Distribution (VADER):\")\n",
    "print(df['sentiment_vader'].value_counts())\n",
    "print(f\"\\nSentiment Distribution (Combined - FINAL):\")\n",
    "print(df['sentiment_final'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1822561b",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# TextBlob sentiment distribution\n",
    "sentiment_tb = df['sentiment_textblob'].value_counts()\n",
    "sentiment_tb.plot(kind='pie', ax=axes[0,0], autopct='%1.1f%%', startangle=90)\n",
    "axes[0,0].set_title('TextBlob Sentiment Distribution')\n",
    "axes[0,0].set_ylabel('')\n",
    "\n",
    "# VADER sentiment distribution\n",
    "sentiment_vader = df['sentiment_vader'].value_counts()\n",
    "sentiment_vader.plot(kind='pie', ax=axes[0,1], autopct='%1.1f%%', startangle=90)\n",
    "axes[0,1].set_title('VADER Sentiment Distribution')\n",
    "axes[0,1].set_ylabel('')\n",
    "\n",
    "# Final combined sentiment distribution\n",
    "sentiment_final = df['sentiment_final'].value_counts()\n",
    "sentiment_final.plot(kind='pie', ax=axes[0,2], autopct='%1.1f%%', startangle=90)\n",
    "axes[0,2].set_title('Combined Sentiment Distribution (FINAL)')\n",
    "axes[0,2].set_ylabel('')\n",
    "\n",
    "# Comparison bar chart\n",
    "comparison_data = pd.DataFrame({\n",
    "    'TextBlob': sentiment_tb,\n",
    "    'VADER': sentiment_vader,\n",
    "    'Combined': sentiment_final\n",
    "}).fillna(0)\n",
    "\n",
    "comparison_data.plot(kind='bar', ax=axes[1,0])\n",
    "axes[1,0].set_title('Sentiment Method Comparison')\n",
    "axes[1,0].set_xlabel('Sentiment')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# VADER compound score distribution\n",
    "axes[1,1].hist(df['vader_compound'], bins=50, color='skyblue', alpha=0.7)\n",
    "axes[1,1].set_title('VADER Compound Score Distribution')\n",
    "axes[1,1].set_xlabel('Compound Score')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].axvline(x=0.05, color='green', linestyle='--', label='Positive threshold')\n",
    "axes[1,1].axvline(x=-0.05, color='red', linestyle='--', label='Negative threshold')\n",
    "axes[1,1].legend()\n",
    "\n",
    "# Sentiment by email domain (top 10)\n",
    "if 'email_domain' in df.columns:\n",
    "    top_domains = df['email_domain'].value_counts().head(10).index\n",
    "    domain_sentiment = df[df['email_domain'].isin(top_domains)].groupby(['email_domain', 'sentiment_final']).size().unstack(fill_value=0)\n",
    "    domain_sentiment.plot(kind='bar', stacked=True, ax=axes[1,2])\n",
    "    axes[1,2].set_title('Final Sentiment by Email Domain (Top 10)')\n",
    "    axes[1,2].set_xlabel('Email Domain')\n",
    "    axes[1,2].set_ylabel('Count')\n",
    "    axes[1,2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/sentiment_analysis_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Agreement analysis\n",
    "agreement_analysis = pd.crosstab(df['sentiment_textblob'], df['sentiment_vader'], margins=True)\n",
    "print(\"\\nAgreement between TextBlob and VADER:\")\n",
    "print(agreement_analysis)\n",
    "\n",
    "# Calculate agreement percentage\n",
    "total_agreements = (df['sentiment_textblob'] == df['sentiment_vader']).sum()\n",
    "agreement_percentage = (total_agreements / len(df)) * 100\n",
    "print(f\"\\nOverall agreement between TextBlob and VADER: {agreement_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228ba81",
   "metadata": {},
   "source": [
    "## 5. Machine Learning-Based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5fa11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TextBlob sentiment as labels for training (in real scenario, you'd have manually labeled data)\n",
    "# For demonstration, we'll use a subset of data with clear sentiments\n",
    "clear_sentiment_mask = df['polarity_score'].abs() > 0.1\n",
    "df_train = df[clear_sentiment_mask].copy()\n",
    "\n",
    "print(f\"Training data shape: {df_train.shape}\")\n",
    "print(f\"Training sentiment distribution:\\n{df_train['sentiment_textblob'].value_counts()}\")\n",
    "\n",
    "# Prepare data for ML models\n",
    "X = df_train['combined_text']\n",
    "y = df_train['sentiment_textblob']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF feature matrix shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aee8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "nb_pred = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, nb_pred):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, nb_pred))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_pred):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5a1c3",
   "metadata": {},
   "source": [
    "## 6. Apply Best Model to Full Dataset and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf110e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset with sentiment analysis results\n",
    "df.to_csv('../data/processed/email_data_with_sentiment.csv', index=False)\n",
    "print(\"Dataset with sentiment analysis saved to '../data/processed/email_data_with_sentiment.csv'\")\n",
    "\n",
    "# Create summary report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 1: SENTIMENT LABELING - SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"- Total messages analyzed: {len(df):,}\")\n",
    "print(f\"- Unique employees: {df['from'].nunique():,}\")\n",
    "print(f\"- Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "print(f\"\\nFinal Sentiment Distribution:\")\n",
    "sentiment_counts = df['sentiment_final'].value_counts()\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"- {sentiment}: {count:,} messages ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nMethod Comparison:\")\n",
    "print(f\"- TextBlob-VADER Agreement: {agreement_percentage:.2f}%\")\n",
    "print(f\"- Combined method used for final labels\")\n",
    "\n",
    "print(f\"\\nSample Results:\")\n",
    "sample_cols = ['Subject', 'sentiment_final', 'vader_compound', 'textblob_polarity']\n",
    "sample_data = df[sample_cols].head(10)\n",
    "print(sample_data.to_string(index=False))\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"- Processed dataset: ../data/processed/email_data_with_sentiment.csv\")\n",
    "print(f\"- Visualization: ../visualizations/sentiment_analysis_comparison.png\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"Task 1 completed successfully!\")\n",
    "print(\"Next: Run Task 2 (Exploratory Data Analysis)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
